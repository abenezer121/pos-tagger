{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /home/abenezer121/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/abenezer121/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NOUN'), ('Vinken', 'NOUN'), (',', '.'), ('61', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), (',', '.'), ('will', 'VERB'), ('join', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('as', 'ADP'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('Nov.', 'NOUN'), ('29', 'NUM'), ('.', '.')], [('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time\n",
    " \n",
    "nltk.download('treebank')\n",
    "nltk.download('universal_tagset')\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n",
    "print(nltk_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training and testing set into 80 20 ratio\n",
    "train_set,test_set =train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('company', 'NOUN'), ('said', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [ tup for sent in train_set for tup in sent ]\n",
    "test_tagged_words = [ tup for sent in test_set for tup in sent ]\n",
    "\n",
    "\n",
    "print(test_tagged_words[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'DET', 'VERB', 'ADV', 'CONJ', 'ADP', '.', 'ADJ', 'PRON', 'PRT', 'NUM', 'NOUN', 'X'}\n"
     ]
    }
   ],
   "source": [
    "#use set datatype to check how many unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)\n",
    " \n",
    "# check total words in vocabulary\n",
    "vocab = {word for word,tag in train_tagged_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)#total number of times the passed tag occurred in train_bag\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "#now calculate the total number of times the passed word occurred as the passed tag.\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    " \n",
    "     \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute  Transition Probability\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DET</th>\n",
       "      <th>VERB</th>\n",
       "      <th>ADV</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>.</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PRT</th>\n",
       "      <th>NUM</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.009918</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.206411</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.635906</td>\n",
       "      <td>0.045134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.133610</td>\n",
       "      <td>0.167956</td>\n",
       "      <td>0.083886</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.092357</td>\n",
       "      <td>0.034807</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.035543</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.110589</td>\n",
       "      <td>0.215930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.071373</td>\n",
       "      <td>0.339022</td>\n",
       "      <td>0.081458</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.119472</td>\n",
       "      <td>0.139255</td>\n",
       "      <td>0.130721</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>0.029868</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.022886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.123491</td>\n",
       "      <td>0.150384</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.055982</td>\n",
       "      <td>0.035126</td>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.060373</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.349067</td>\n",
       "      <td>0.009330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.320931</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>0.038724</td>\n",
       "      <td>0.107062</td>\n",
       "      <td>0.069603</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.063275</td>\n",
       "      <td>0.323589</td>\n",
       "      <td>0.034548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.172192</td>\n",
       "      <td>0.089690</td>\n",
       "      <td>0.052569</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>0.092908</td>\n",
       "      <td>0.092372</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.068769</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.078210</td>\n",
       "      <td>0.218539</td>\n",
       "      <td>0.025641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.080583</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.021748</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.020971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.484738</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>0.041913</td>\n",
       "      <td>0.070615</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.212756</td>\n",
       "      <td>0.088383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.101370</td>\n",
       "      <td>0.401174</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.045010</td>\n",
       "      <td>0.082975</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.250489</td>\n",
       "      <td>0.012133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.037487</td>\n",
       "      <td>0.119243</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.184220</td>\n",
       "      <td>0.351660</td>\n",
       "      <td>0.202428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.149134</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.042454</td>\n",
       "      <td>0.176827</td>\n",
       "      <td>0.240094</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.262344</td>\n",
       "      <td>0.028825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.056890</td>\n",
       "      <td>0.206419</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.142226</td>\n",
       "      <td>0.160869</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.185086</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.075726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DET      VERB       ADV      CONJ       ADP         .       ADJ  \\\n",
       "DET   0.006037  0.040247  0.012074  0.000431  0.009918  0.017393  0.206411   \n",
       "VERB  0.133610  0.167956  0.083886  0.005433  0.092357  0.034807  0.066390   \n",
       "ADV   0.071373  0.339022  0.081458  0.006982  0.119472  0.139255  0.130721   \n",
       "CONJ  0.123491  0.150384  0.057080  0.000549  0.055982  0.035126  0.113611   \n",
       "ADP   0.320931  0.008479  0.014553  0.001012  0.016958  0.038724  0.107062   \n",
       ".     0.172192  0.089690  0.052569  0.060079  0.092908  0.092372  0.046132   \n",
       "ADJ   0.005243  0.011456  0.005243  0.016893  0.080583  0.066019  0.063301   \n",
       "PRON  0.009567  0.484738  0.036902  0.005011  0.022323  0.041913  0.070615   \n",
       "PRT   0.101370  0.401174  0.009393  0.002348  0.019569  0.045010  0.082975   \n",
       "NUM   0.003570  0.020707  0.003570  0.014281  0.037487  0.119243  0.035345   \n",
       "NOUN  0.013106  0.149134  0.016895  0.042454  0.176827  0.240094  0.012584   \n",
       "X     0.056890  0.206419  0.025754  0.010379  0.142226  0.160869  0.017682   \n",
       "\n",
       "          PRON       PRT       NUM      NOUN         X  \n",
       "DET   0.003306  0.000287  0.022855  0.635906  0.045134  \n",
       "VERB  0.035543  0.030663  0.022836  0.110589  0.215930  \n",
       "ADV   0.012025  0.014740  0.029868  0.032196  0.022886  \n",
       "CONJ  0.060373  0.004391  0.040615  0.349067  0.009330  \n",
       "ADP   0.069603  0.001266  0.063275  0.323589  0.034548  \n",
       ".     0.068769  0.002789  0.078210  0.218539  0.025641  \n",
       "ADJ   0.000194  0.011456  0.021748  0.696893  0.020971  \n",
       "PRON  0.006834  0.014123  0.006834  0.212756  0.088383  \n",
       "PRT   0.017613  0.001174  0.056751  0.250489  0.012133  \n",
       "NUM   0.001428  0.026062  0.184220  0.351660  0.202428  \n",
       "NOUN  0.004659  0.043935  0.009144  0.262344  0.028825  \n",
       "X     0.054200  0.185086  0.003075  0.061695  0.075726  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n",
    " \n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "display(tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "     \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                 \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "             \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "random.seed(1234)      #define a random seed to get same sentences when run multiple times\n",
    " \n",
    "# choose random 10 numbers\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
    " \n",
    "# list of 10 sents on which we test the model\n",
    "test_run = [test_set[i] for i in rndom]\n",
    " \n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    " \n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  37.67053031921387\n",
      "Viterbi Algorithm Accuracy:  93.77990430622009\n"
     ]
    }
   ],
   "source": [
    "#Here We will only test 10 sentences to check the accuracy\n",
    "#as testing the whole training set takes huge amount of time\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    " \n",
    "print(\"Time taken in seconds: \", difference)\n",
    " \n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    " \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
